{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "os.chdir('C:\\\\Users\\\\yaffy\\\\Desktop\\\\python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    @nicktanner799 @ayushmalla77 @LFC Sad news but what does this justify anybody being religious or not if I may ask\n",
      "Name: text, dtype: object\n",
      "0    @nicktanner799 @ayushmalla77 @LFC Sad news justify anybody religious I may ask\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('liverp_df.csv')\n",
    "test_text = df['text'][:1]\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "replace_set = stopwords.words('english')\n",
    "no_stopwords = test_text.str.split(' ').apply(lambda x: ' '.join(k for k in x if k not in replace_set))\n",
    "\n",
    "print test_text\n",
    "print no_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@P17Jamie @LFC ðŸ˜‚ðŸ˜‚I guess we will see broer, how have u been bro?\n",
      "@P17Jamie @LFC I guess we will see broer, how have u been bro?\n"
     ]
    }
   ],
   "source": [
    "test_text2 = df['text'][83]\n",
    "print(test_text2)\n",
    "test_text2_decoding = test_text2.decode(\"utf8\").encode('ascii','ignore')\n",
    "\n",
    "import HTMLParser\n",
    "html_parser = HTMLParser.HTMLParser()\n",
    "no_html = html_parser.unescape(test_text2_decoding)\n",
    "print(no_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@P17Jamie @LFC I guess we will see broer, how have u been bro?\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "no_urls = re.sub(r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+','',no_html)\n",
    "print(no_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  I guess we will see broer, how have u been bro?\n"
     ]
    }
   ],
   "source": [
    "no_atmention = re.sub(r'@[\\w_]+','', no_urls)\n",
    "print(no_atmention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@ThreadsForReds @VerdierOfficial @LFC #lfc @LFC The reality is any clubs progress is rightfully judged on there domâ€¦ https://t.co/pcy95xVj2v\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'@ThreadsForReds @VerdierOfficial @LFC #lfc @LFC The reality is any clubs progress is rightfully judged on there dom\\xe2\\x80\\xa6 https://t.co/pcy95xVj2v'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text3 = df['text'][11]\n",
    "print(test_text3)\n",
    "\n",
    "re.sub(r'[:=;] [oO\\-]?[D\\)\\]\\(\\]/\\\\OpP]', '', test_text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    @nicktanner799 @ayushmalla77 @LFC Sad news but what does this justify anybody being religious or not if I may ask                      \n",
       "1    @EL_PISTOLERO_07 @LFC Why would you want De Vrij. Or Yaya Toure??? https://t.co/EpfuSefuac                                             \n",
       "2    Follow @LFC @LiverpudlianLFC @OfficialLFC_ID #ynwa #liverpudlian #comeonyoureds #dontbuythesun #LFC #liverpoolâ€¦ https://t.co/9eib9mvGrH\n",
       "3    @EL_PISTOLERO_07 @LFC He has already signed FOR INTER                                                                                  \n",
       "4    @EL_PISTOLERO_07 @an_esq10 @LFC De vrij just match fixed Inters win so he could play in CL. Doubt he wants LFC #LazioInter             \n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_liverp = pd.read_csv('liverp_df.csv')\n",
    "demo = df_liverp['text'][:5] # demo testing with 10 texts \n",
    "demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yaffy\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:2: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    @nicktanner799 @ayushmalla77 @LFC Sad news justify anybody religious I may ask                                                         \n",
       "1    @EL_PISTOLERO_07 @LFC Why would want De Vrij. Or Yaya Toure??? https://t.co/EpfuSefuac                                                 \n",
       "2    Follow @LFC @LiverpudlianLFC @OfficialLFC_ID #ynwa #liverpudlian #comeonyoureds #dontbuythesun #LFC #liverpoolâ€¦ https://t.co/9eib9mvGrH\n",
       "3    @EL_PISTOLERO_07 @LFC He already signed FOR INTER                                                                                      \n",
       "4    @EL_PISTOLERO_07 @an_esq10 @LFC De vrij match fixed Inters win could play CL. Doubt wants LFC #LazioInter                              \n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_set = stopwords.words('english') \n",
    "demo = demo.str.split(' ').apply(lambda x: ' '.join(k for k in x if k not in replace_set)) # texts with no stop-words\n",
    "demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dic = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \n",
    "             \"can't've\": \"cannot have\", \"'cause\": \"because\", \"could've\": \"could have\", \n",
    "             \"couldn't\": \"could not\", \"couldn't've\": \"could not have\",\"didn't\": \"did not\", \n",
    "             \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\",  \n",
    "             \"hadn't've\": \"had not have\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \n",
    "             \"he'd\": \"he would\", \"he'd've\": \"he would have\", \"he'll\": \"he will\", \n",
    "             \"he'll've\": \"he will have\", \"he's\": \"he is\", \"how'd\": \"how did\", \n",
    "             \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \n",
    "             \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \n",
    "             \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \n",
    "             \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\", \n",
    "             \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \n",
    "             \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \n",
    "             \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \n",
    "             \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \n",
    "             \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \n",
    "             \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \n",
    "             \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \n",
    "             \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n",
    "             \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \n",
    "             \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \n",
    "             \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \n",
    "             \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \n",
    "             \"this's\": \"this is\",\n",
    "             \"that'd\": \"that would\", \"that'd've\": \"that would have\",\"that's\": \"that is\", \n",
    "             \"there'd\": \"there would\", \"there'd've\": \"there would have\",\"there's\": \"there is\", \n",
    "             \"here's\": \"here is\",\n",
    "             \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \n",
    "             \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\",\n",
    "             \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \n",
    "             \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \n",
    "             \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\",\n",
    "             \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\", \n",
    "             \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \n",
    "             \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \n",
    "             \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \n",
    "             \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \n",
    "             \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\",\n",
    "             \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \n",
    "             \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "             \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "             \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \n",
    "             \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yaffy\\Anaconda2\\lib\\encodings\\utf_8_sig.py:19: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  if input[:3] == codecs.BOM_UTF8:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'sad news justify anybody religious may ask',\n",
       " u'why would want de vrij or yaya toure',\n",
       " u'follow',\n",
       " u'he already signed for inter',\n",
       " u'de vrij match fixed inters win could play cl doubt wants lfc']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "tok = WordPunctTokenizer()\n",
    "\n",
    "pat1 = r'@[\\w_]+' # @-mention\n",
    "pat2 = r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+' # URLs\n",
    "pat3 = r'[:=;] [oO\\-]?[D\\)\\]\\(\\]/\\\\OpP]' # emoticons\n",
    "pat4 = r'(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)' # hash-tags\n",
    "pat5 = r'www.[^ ]+' # additions to URLs, texts with 'www..'\n",
    "combined_pat = r'|'.join((pat1, pat2, pat3,pat4,pat5))\n",
    "\n",
    "\n",
    "split_pattern = re.compile(r'\\b(' + '|'.join(split_dic.keys()) + r')\\b')\n",
    "\n",
    "\n",
    "def tweet_cleaner(demo):\n",
    "    soup = BeautifulSoup(demo, 'lxml') # HTML\n",
    "    souped = soup.get_text()\n",
    "    try:\n",
    "        clean = souped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "        # decoding text with 'utf-8-sig'\n",
    "    except:\n",
    "        clean = souped\n",
    "    \n",
    "    stripped = re.sub(combined_pat, '', clean)\n",
    "    lower_case = stripped.lower()\n",
    "    split_handled = split_pattern.sub(lambda x: split_dic[x.group()], lower_case)\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", split_handled)\n",
    "    spell_corrected = re.sub(r'(.)\\1+', r'\\1\\1', letters_only)\n",
    "    # check if there's any spell with repeated characters such as 'soooo good', and transform it as 'soo good' or 'loove it'. Not a perfect solution but could reduct feature space by making\n",
    "    words = [x for x in tok.tokenize(spell_corrected) if len(x) > 1]\n",
    "\n",
    "    return (\" \".join(words)).strip()\n",
    "\n",
    "test_result = []\n",
    "for t in demo:\n",
    "    test_result.append(tweet_cleaner(t))\n",
    "    # [tweet_cleaner(t) for t in demo]\n",
    "\n",
    "test_result # cleaning texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_liverp = pd.read_csv('liverp_df.csv')\n",
    "replace_set = stopwords.words('english') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145509\n",
      "145504\n"
     ]
    }
   ],
   "source": [
    "print(len(df_liverp))\n",
    "df_liverp = df_liverp.dropna(subset=['text'], how='all')\n",
    "print(len(df_liverp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yaffy\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:1: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_liverp['text'] = df_liverp['text'].str.split(' ').apply(lambda x: ' '.join(k for k in x if k not in replace_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yaffy\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"https://t.co/kets1o8lxy\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\yaffy\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"https://t.co/qctKmN64hE\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\yaffy\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"https://t.co/mb2XQ2Nyqa\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\yaffy\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"https://t.co/2p1zfXp38E\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    }
   ],
   "source": [
    "df_liverp['clean_text'] = [tweet_cleaner(t) for t in df_liverp.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_drop = ['text', 'extended_tweet','ideo_score','friends','followers','listed','name','screen_name','id']\n",
    "clean_liverp = df_liverp.drop(col_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 145504 entries, 0 to 145503\n",
      "Data columns (total 2 columns):\n",
      "created_at    145504 non-null object\n",
      "clean_text    145504 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.2+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mon May 21 01:15:18 +0000 2018</td>\n",
       "      <td>sad news justify anybody religious may ask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mon May 21 01:16:48 +0000 2018</td>\n",
       "      <td>why would want de vrij or yaya toure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mon May 21 01:23:34 +0000 2018</td>\n",
       "      <td>follow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mon May 21 01:23:53 +0000 2018</td>\n",
       "      <td>he already signed for inter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mon May 21 01:28:09 +0000 2018</td>\n",
       "      <td>de vrij match fixed inters win could play cl doubt wants lfc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at  \\\n",
       "0  Mon May 21 01:15:18 +0000 2018   \n",
       "1  Mon May 21 01:16:48 +0000 2018   \n",
       "2  Mon May 21 01:23:34 +0000 2018   \n",
       "3  Mon May 21 01:23:53 +0000 2018   \n",
       "4  Mon May 21 01:28:09 +0000 2018   \n",
       "\n",
       "                                                     clean_text  \n",
       "0  sad news justify anybody religious may ask                    \n",
       "1  why would want de vrij or yaya toure                          \n",
       "2  follow                                                        \n",
       "3  he already signed for inter                                   \n",
       "4  de vrij match fixed inters win could play cl doubt wants lfc  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_liverp.dropna(inplace=True)\n",
    "clean_liverp.reset_index(drop=True,inplace=True)\n",
    "\n",
    "print(clean_liverp.info())\n",
    "clean_liverp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "clean_liverp['created_at'] = pd.to_datetime(clean_liverp.created_at).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-05-21</td>\n",
       "      <td>sad news justify anybody religious may ask</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-05-21</td>\n",
       "      <td>why would want de vrij or yaya toure</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-05-21</td>\n",
       "      <td>follow</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-05-21</td>\n",
       "      <td>he already signed for inter</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-05-21</td>\n",
       "      <td>de vrij match fixed inters win could play cl doubt wants lfc</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   created_at                                                    clean_text  \\\n",
       "0  2018-05-21  sad news justify anybody religious may ask                     \n",
       "1  2018-05-21  why would want de vrij or yaya toure                           \n",
       "2  2018-05-21  follow                                                         \n",
       "3  2018-05-21  he already signed for inter                                    \n",
       "4  2018-05-21  de vrij match fixed inters win could play cl doubt wants lfc   \n",
       "\n",
       "  period  \n",
       "0         \n",
       "1         \n",
       "2         \n",
       "3         \n",
       "4         "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_liverp['period'] = ' '\n",
    " \n",
    "\n",
    "clean_liverp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_liverp.to_csv('clean_liv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>period</th>\n",
       "      <th>team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sad news justify anybody religious may ask</td>\n",
       "      <td>pre-event</td>\n",
       "      <td>Liverpool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why would want de vrij or yaya toure</td>\n",
       "      <td>pre-event</td>\n",
       "      <td>Liverpool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>follow</td>\n",
       "      <td>pre-event</td>\n",
       "      <td>Liverpool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>he already signed for inter</td>\n",
       "      <td>pre-event</td>\n",
       "      <td>Liverpool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>de vrij match fixed inters win could play cl doubt wants lfc</td>\n",
       "      <td>pre-event</td>\n",
       "      <td>Liverpool</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     clean_text     period  \\\n",
       "0  sad news justify anybody religious may ask                    pre-event   \n",
       "1  why would want de vrij or yaya toure                          pre-event   \n",
       "2  follow                                                        pre-event   \n",
       "3  he already signed for inter                                   pre-event   \n",
       "4  de vrij match fixed inters win could play cl doubt wants lfc  pre-event   \n",
       "\n",
       "        team  \n",
       "0  Liverpool  \n",
       "1  Liverpool  \n",
       "2  Liverpool  \n",
       "3  Liverpool  \n",
       "4  Liverpool  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_liverp = pd.read_csv('clean_liverp.csv')\n",
    "clean_liverp.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
